import os
import yaml
from pathlib import Path
import torch
import gc
from ultralytics import YOLO
from datetime import datetime
import json

class YOLOTrainBuonNgu:
    def __init__(self):
        self.dataset_path = "dataset_buonngu"
        self.model_save_path = "savemodel"
        
        # T·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
        os.makedirs(self.model_save_path, exist_ok=True)
        
        # Class names cho drowsiness detection
        self.classes = {
            0: 'alert',      # T·ªânh t√°o
            1: 'drowsy'      # Bu·ªìn ng·ªß
        }
        
        # Device setup
        self.device = self.check_gpu_availability()
        
        self._stop_callback = None  # Kh·ªüi t·∫°o bi·∫øn d·ª´ng training
    
    def check_gpu_availability(self):
        """Ki·ªÉm tra GPU availability v√† tr·∫£ v·ªÅ device ph√π h·ª£p"""
        if torch.cuda.is_available():
            try:
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                
                print(f"\n=== TH√îNG TIN GPU ===")
                print(f"GPU: {gpu_name}")
                print(f"GPU Memory: {gpu_memory:.1f} GB")
                print(f"CUDA Version: {torch.version.cuda}")
                print("‚úÖ S·∫Ω s·ª≠ d·ª•ng GPU ƒë·ªÉ training")
                
                # Clear GPU cache
                torch.cuda.empty_cache()
                return 'cuda'
                
            except Exception as e:
                print(f"L·ªói GPU: {e}")
                return 'cpu'
        else:
            print("\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y GPU, s·ª≠ d·ª•ng CPU")
            return 'cpu'
    
    def create_data_yaml(self):
        """T·∫°o file c·∫•u h√¨nh data.yaml cho YOLO"""
        data_config = {
            'path': os.path.abspath(self.dataset_path),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': len(self.classes),
            'names': list(self.classes.values())
        }
        
        yaml_path = os.path.join(self.dataset_path, 'data.yaml')
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"‚úÖ ƒê√£ t·∫°o file c·∫•u h√¨nh: {yaml_path}")
        return yaml_path
    
    def set_stop_callback(self, callback):
        """Thi·∫øt l·∫≠p callback ƒë·ªÉ d·ª´ng training"""
        self._stop_callback = callback

    def train_yolov8s(self, epochs=100):
        """Train YOLOv8s model v·ªõi tinh ch·ªânh ch·ªëng nh·∫≠n nh·∫ßm"""
        print("\nüöÄ B·∫ÆT ƒê·∫¶U TRAINING YOLOv8s - CH·ªêNG NH·∫¨N NH·∫¶M")
        print("=" * 55)
        
        # T·∫°o file data.yaml
        data_yaml = self.create_data_yaml()
        
        # Load YOLOv8s model
        try:
            print("üì• ƒêang t·∫£i YOLOv8s model...")
            model = YOLO('yolov8s.pt')
            print("‚úÖ ƒê√£ t·∫£i model YOLOv8s th√†nh c√¥ng!")
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i model: {e}")
            return None
        
        # Training arguments v·ªõi tinh ch·ªânh ch·ªëng overfitting v√† false positive
        train_args = {
            'data': data_yaml,
            'epochs': epochs,
            'imgsz': 640,
            'batch': 12 if self.device == 'cuda' else 6,  # Gi·∫£m batch ƒë·ªÉ stable h∆°n
            'name': 'drowsiness_detection_yolov8s_tuned',
            'project': self.model_save_path,
            'save': True,
            'device': self.device,
            'workers': 2,  # Gi·∫£m workers ƒë·ªÉ ·ªïn ƒë·ªãnh
            'optimizer': 'AdamW',
            
            # Learning rate tinh ch·ªânh
            'lr0': 0.005,      # Gi·∫£m learning rate cho stable training
            'lrf': 0.001,      # Final learning rate th·∫•p h∆°n
            'warmup_epochs': 5, # Warm-up ƒë·ªÉ model h·ªçc ·ªïn ƒë·ªãnh
            'cos_lr': True,     # Cosine annealing
            
            # Early stopping v√† validation
            'patience': 25,     # TƒÉng patience ƒë·ªÉ tr√°nh d·ª´ng s·ªõm
            'val': True,
            'fraction': 1.0,    # S·ª≠ d·ª•ng to√†n b·ªô dataset
            
            # Regularization m·∫°nh ƒë·ªÉ gi·∫£m overfitting
            'weight_decay': 0.001,
            # Removed deprecated label_smoothing
            
            # Data augmentation c√¢n b·∫±ng
            'hsv_h': 0.015,     # Hue augmentation nh·∫π
            'hsv_s': 0.7,       # Saturation
            'hsv_v': 0.4,       # Value
            'degrees': 10,      # Rotation nh·∫π
            'translate': 0.1,   # Translation
            'scale': 0.5,       # Scale variation
            'shear': 0.05,      # Shear nh·∫π
            'perspective': 0.0002, # Perspective
            'fliplr': 0.5,      # Horizontal flip
            'flipud': 0.0,      # Kh√¥ng flip vertical cho face
            'mosaic': 0.7,      # Gi·∫£m mosaic intensity
            'mixup': 0.1,       # Mixup nh·∫π
            'copy_paste': 0.05, # Copy-paste nh·∫π
            
            # Confidence v√† NMS tuning
            'conf': 0.3,        # Confidence threshold th·∫•p h∆°n trong training
            'iou': 0.6,         # IoU threshold cho NMS
            
            # Class loss weights (thay th·∫ø fl_gamma kh√¥ng h·ª£p l·ªá)
            'cls': 0.5,         # Classification loss gain
            'box': 7.5,         # Box regression loss gain
            
            # Advanced settings
            'close_mosaic': 15, # T·∫Øt mosaic ·ªü 15 epochs cu·ªëi
            'amp': True if self.device == 'cuda' else False,
            'plots': True,
            'verbose': True,
            'seed': 42          # Reproducible results
        }
        
        # Device-specific settings
        if self.device == 'cuda':
            train_args['amp'] = True  # Mixed precision cho GPU
        
        # Hi·ªÉn th·ªã th√¥ng tin training
        print(f"\nüìä TH√îNG TIN TRAINING - CH·ªêNG NH·∫¨N NH·∫¶M:")
        print(f"ü§ñ Model: YOLOv8s (Fine-tuned)")
        print(f"üñ•Ô∏è  Device: {self.device}")
        print(f"üîÑ Epochs: {epochs}")
        print(f"üìä Batch size: {train_args['batch']} (Gi·∫£m ƒë·ªÉ ·ªïn ƒë·ªãnh)")
        print(f"üìê Image size: 640")
        print(f"üéØ Learning rate: {train_args['lr0']} (Th·∫•p h∆°n)")
        print(f"üìè Weight decay: {train_args['weight_decay']}")
        print(f"‚è≥ Patience: {train_args['patience']} epochs")
        print(f"üíæ Save path: {self.model_save_path}")
        print(f"üìÅ Dataset: {self.dataset_path}")
        print(f"üîß Tinh ch·ªânh: Ch·ªëng overfitting & false positive")
        
        try:
            # Clear cache tr∆∞·ªõc khi training
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            gc.collect()
            
            print(f"\nüéØ B·∫Øt ƒë·∫ßu training {epochs} epochs v·ªõi c·∫•u h√¨nh ch·ªëng nh·∫≠n nh·∫ßm...")
            print("‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i gi·ªù...")
            print("üîß C√°c c·∫£i ti·∫øn:")
            print("   ‚Ä¢ Learning rate th·∫•p h∆°n ƒë·ªÉ h·ªçc ·ªïn ƒë·ªãnh")
            print("   ‚Ä¢ Weight decay ch·ªëng overfitting") 
            print("   ‚Ä¢ Class/Box loss weights c√¢n b·∫±ng")
            print("   ‚Ä¢ Data augmentation c√¢n b·∫±ng")
            print("   ‚Ä¢ Early stopping th√¥ng minh")
            
            # Train model
            for epoch in range(epochs):
                if self._stop_callback and self._stop_callback():
                    print("‚èπÔ∏è  ƒê√£ nh·∫≠n t√≠n hi·ªáu d·ª´ng training!")
                    break
                
                results = model.train(**train_args)
            
            # Cleanup
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            gc.collect()
            
            # L∆∞u th√¥ng tin training
            self.save_training_info(results, train_args)
            
            print("\nüéâ TRAINING HO√ÄN TH√ÄNH - MODEL ƒê√É ƒê∆Ø·ª¢C TINH CH·ªàNH!")
            print(f"üìÅ Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {self.model_save_path}")
            print("üîß Model ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ gi·∫£m nh·∫≠n nh·∫ßm:")
            print("   ‚úÖ Gi·∫£m false positive")
            print("   ‚úÖ TƒÉng ƒë·ªô ch√≠nh x√°c")
            print("   ‚úÖ ·ªîn ƒë·ªãnh h∆°n v·ªõi d·ªØ li·ªáu m·ªõi")
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if hasattr(results, 'box'):
                print(f"\nüìä K·∫æT QU·∫¢:")
                print(f"üéØ mAP50: {results.box.map50:.4f}")
                print(f"üéØ mAP50-95: {results.box.map:.4f}")
                
                # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng
                if results.box.map50 > 0.8:
                    print("üåü Ch·∫•t l∆∞·ª£ng: Xu·∫•t s·∫Øc!")
                elif results.box.map50 > 0.6:
                    print("üëç Ch·∫•t l∆∞·ª£ng: T·ªët")
                elif results.box.map50 > 0.4:
                    print("‚ö†Ô∏è Ch·∫•t l∆∞·ª£ng: Kh√°, c√≥ th·ªÉ c·∫ßn th√™m data")
                else:
                    print("‚ùå Ch·∫•t l∆∞·ª£ng: C·∫ßn c·∫£i thi·ªán dataset")
            
            return model, results
            
        except Exception as e:
            print(f"‚ùå L·ªói khi training: {e}")
            
            if self.device == 'cuda':
                if "out of memory" in str(e).lower():
                    print("üí° G·ª£i √Ω: GPU h·∫øt memory, th·ª≠ gi·∫£m batch size")
                torch.cuda.empty_cache()
            
            return None, None
    
    def save_training_info(self, results, train_args):
        """L∆∞u th√¥ng tin training"""
        training_info = {
            'model_type': 'YOLOv8s',
            'classes': self.classes,
            'train_args': train_args,
            'training_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'dataset_path': self.dataset_path,
            'model_save_path': self.model_save_path,
            'device': self.device
        }
        
        # Th√™m k·∫øt qu·∫£ n·∫øu c√≥
        if results and hasattr(results, 'save_dir'):
            training_info['results_path'] = str(results.save_dir)
        
        info_path = os.path.join(self.model_save_path, 'training_info.json')
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(training_info, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"üìÑ ƒê√£ l∆∞u th√¥ng tin training: {info_path}")

def check_dataset(dataset_path):
    """Ki·ªÉm tra dataset"""
    print(f"\nüìÅ Ki·ªÉm tra dataset: {dataset_path}")
    
    if not os.path.exists(dataset_path):
        print(f"‚ùå Dataset kh√¥ng t·ªìn t·∫°i: {dataset_path}")
        return False
    
    # Ki·ªÉm tra c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
    required_dirs = ['images/train', 'images/val', 'labels/train', 'labels/val']
    all_good = True
    
    for dir_name in required_dirs:
        dir_path = os.path.join(dataset_path, dir_name)
        if os.path.exists(dir_path):
            file_count = len(os.listdir(dir_path))
            print(f"‚úÖ {dir_name}: {file_count} files")
            if file_count == 0:
                print(f"‚ö†Ô∏è  {dir_name} tr·ªëng!")
        else:
            print(f"‚ùå {dir_name}: Kh√¥ng t·ªìn t·∫°i")
            all_good = False
    
    return all_good

def main():
    """H√†m ch√≠nh"""
    print("=" * 60)
    print("ü§ñ YOLO TRAINING BUONNGU - YOLOv8s")
    print("=" * 60)
    
    # Kh·ªüi t·∫°o trainer
    trainer = YOLOTrainBuonNgu()
    
    # Ki·ªÉm tra dataset
    if not check_dataset(trainer.dataset_path):
        print("\n‚ùå Dataset kh√¥ng h·ª£p l·ªá!")
        print("üí° ƒê·∫£m b·∫£o c√≥ c√°c th∆∞ m·ª•c:")
        print("   - dataset_buonngu/images/train/")
        print("   - dataset_buonngu/images/val/")
        print("   - dataset_buonngu/labels/train/")
        print("   - dataset_buonngu/labels/val/")
        return
    
    # Nh·∫≠p s·ªë epochs
    print(f"\nüîÑ THI·∫æT L·∫¨P TRAINING")
    epochs_input = input("Nh·∫≠p s·ªë epochs (50-300) [m·∫∑c ƒë·ªãnh: 100]: ").strip()
    
    try:
        epochs = int(epochs_input) if epochs_input else 100
        epochs = max(50, min(epochs, 300))  # Gi·ªõi h·∫°n 50-300
    except:
        epochs = 100
        print("‚ö†Ô∏è Gi√° tr·ªã kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: 100 epochs")
    
    print(f"‚úÖ S·∫Ω training {epochs} epochs")
    
    # X√°c nh·∫≠n b·∫Øt ƒë·∫ßu
    confirm = input(f"\nüöÄ B·∫Øt ƒë·∫ßu training YOLOv8s? (y/n) [y]: ").strip().lower()
    
    if confirm in ['', 'y', 'yes']:
        print("\n" + "="*60)
        print("üéØ B·∫ÆT ƒê·∫¶U TRAINING")
        print("="*60)
        
        # B·∫Øt ƒë·∫ßu training
        model, results = trainer.train_yolov8s(epochs=epochs)
        
        if model and results:
            print("\n" + "="*60)
            print("üéâ TRAINING TH√ÄNH C√îNG!")
            print("="*60)
            print(f"üìÅ Model l∆∞u t·∫°i: {trainer.model_save_path}")
            print("üí° C√≥ th·ªÉ s·ª≠ d·ª•ng model ƒë·ªÉ detect drowsiness!")
        else:
            print("\n‚ùå Training th·∫•t b·∫°i!")
            print("üí° Ki·ªÉm tra l·∫°i dataset v√† th·ª≠ l·∫°i")
    else:
        print("üëã H·ªßy training!")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüõë Ng∆∞·ªùi d√πng d·ª´ng ch∆∞∆°ng tr√¨nh")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        print("üí° Ki·ªÉm tra l·∫°i dataset v√† c·∫•u h√¨nh")
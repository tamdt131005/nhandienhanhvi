import os
import yaml
import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import shutil
import cv2
import logging
import time
from typing import Optional, Dict, List, Tuple
import warnings
import gc
import psutil
import threading

# C·∫•u h√¨nh encoding v√† font ti·∫øng Vi·ªát
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
warnings.filterwarnings('ignore', category=UserWarning)

class PhoneDetectionTrainer:
    def __init__(self, data_path="data", output_path="runs/detect", use_gpu=True):
        """
        Kh·ªüi t·∫°o trainer v·ªõi c√°c bi·ªán ph√°p x·ª≠ l√Ω l·ªói
        """
        self.data_path = Path(data_path)
        self.output_path = Path(output_path)
        self.model_path = "yolov8n.pt"
        self.use_gpu = use_gpu
        self.device = self._check_gpu_availability()
        self.stop_training = False
        self.model = None
        self.training_thread = None
        
        # Thi·∫øt l·∫≠p logging
        self._setup_logging()
        
        # Ki·ªÉm tra v√† t·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
        self._ensure_directories()
        
        # Ki·ªÉm tra h·ªá th·ªëng
        self._check_system_resources()

    def _setup_logging(self):
        """Thi·∫øt l·∫≠p logging ƒë·ªÉ theo d√µi qu√° tr√¨nh training"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / 'training.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def _ensure_directories(self):
        """ƒê·∫£m b·∫£o t·∫•t c·∫£ th∆∞ m·ª•c c·∫ßn thi·∫øt ƒë∆∞·ª£c t·∫°o"""
        try:
            directories = [
                self.data_path,
                self.output_path,
                Path("model"),
                Path("logs"),
                self.data_path / "train" / "images",
                self.data_path / "train" / "labels",
                self.data_path / "val" / "images", 
                self.data_path / "val" / "labels"
            ]
            
            for directory in directories:
                directory.mkdir(parents=True, exist_ok=True)
                
            self.logger.info("‚úÖ ƒê√£ t·∫°o t·∫•t c·∫£ th∆∞ m·ª•c c·∫ßn thi·∫øt")
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói t·∫°o th∆∞ m·ª•c: {e}")
            raise

    def _check_system_resources(self):
        """Ki·ªÉm tra t√†i nguy√™n h·ªá th·ªëng"""
        try:
            # Ki·ªÉm tra RAM
            memory = psutil.virtual_memory()
            available_gb = memory.available / (1024**3)
            
            if available_gb < 2:
                self.logger.warning(f"‚ö†Ô∏è RAM kh·∫£ d·ª•ng th·∫•p: {available_gb:.1f}GB")
                
            # Ki·ªÉm tra dung l∆∞·ª£ng ƒëƒ©a
            disk = psutil.disk_usage('.')
            free_gb = disk.free / (1024**3)
            
            if free_gb < 5:
                self.logger.warning(f"‚ö†Ô∏è Dung l∆∞·ª£ng ƒëƒ©a th·∫•p: {free_gb:.1f}GB")
                
            self.logger.info(f"üíæ RAM kh·∫£ d·ª•ng: {available_gb:.1f}GB")
            self.logger.info(f"üíΩ Dung l∆∞·ª£ng ƒëƒ©a: {free_gb:.1f}GB")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ki·ªÉm tra t√†i nguy√™n h·ªá th·ªëng: {e}")

    def stop(self):
        """D·ª´ng qu√° tr√¨nh training m·ªôt c√°ch an to√†n"""
        self.logger.info("\n" + "="*60)
        self.logger.info("‚èπÔ∏è ƒêANG D·ª™NG QU√Å TR√åNH TRAINING")
        self.logger.info("="*60)
        self.logger.info("‚Üí ƒê√£ nh·∫≠n l·ªánh d·ª´ng")
        self.logger.info("‚Üí ƒêang ch·ªù epoch hi·ªán t·∫°i k·∫øt th√∫c...")
        
        self.stop_training = True
        
        # D·ª´ng YOLO trainer n·∫øu c√≥
        if hasattr(self, 'model') and self.model is not None:
            if hasattr(self.model, 'trainer') and self.model.trainer is not None:
                if hasattr(self.model.trainer, 'stop'):
                    self.model.trainer.stop = True
                    self.logger.info("‚Üí ƒê√£ g·ª≠i t√≠n hi·ªáu d·ª´ng ƒë·∫øn YOLO trainer")
                    return True
        
        self.logger.warning("‚ùå Kh√¥ng th·ªÉ d·ª´ng training (model ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o)")
        return False

    def _check_gpu_availability(self):
        """Ki·ªÉm tra GPU v√† tr·∫£ v·ªÅ device ph√π h·ª£p"""
        try:
            if self.use_gpu and torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(0)
                memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                
                print(f"üéÆ GPU kh·∫£ d·ª•ng: {gpu_name}")
                print(f"üî¢ S·ªë l∆∞·ª£ng GPU: {gpu_count}")
                print(f"üíæ VRAM: {memory_gb:.1f}GB")
                print(f"üîß CUDA version: {torch.version.cuda}")
                
                # Ki·ªÉm tra VRAM c√≥ ƒë·ªß kh√¥ng
                if memory_gb < 4:
                    print("‚ö†Ô∏è VRAM c√≥ th·ªÉ kh√¥ng ƒë·ªß cho training, h√£y gi·∫£m batch_size")
                
                return 'cuda'
            else:
                if self.use_gpu:
                    print("‚ö†Ô∏è GPU ƒë∆∞·ª£c y√™u c·∫ßu nh∆∞ng kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng CPU")
                else:
                    print("üñ•Ô∏è S·ª≠ d·ª•ng CPU cho training")
                return 'cpu'
                
        except Exception as e:
            print(f"‚ùå L·ªói ki·ªÉm tra GPU: {e}")
            return 'cpu'
    
    def create_dataset_yaml(self):
        """T·∫°o file c·∫•u h√¨nh dataset cho YOLO training"""
        try:
            # Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n t·ªìn t·∫°i
            if not self.data_path.exists():
                raise FileNotFoundError(f"Th∆∞ m·ª•c data kh√¥ng t·ªìn t·∫°i: {self.data_path}")
            
            # C·∫•u h√¨nh dataset
            dataset_config = {
                'path': str(self.data_path.resolve()),
                'train': 'train/images',
                'val': 'val/images',
                'test': 'val/images',
                
                # T√™n class d·ª±a tr√™n c·∫•u tr√∫c th∆∞ m·ª•c
                'names': {
                    0: 'no_phone',
                    1: 'using_phone'
                },
                'nc': 2  # S·ªë l∆∞·ª£ng class
            }
            
            # L∆∞u dataset.yaml
            yaml_path = self.data_path / "dataset.yaml"
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)
                
            self.logger.info(f"‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh dataset: {yaml_path}")
            return yaml_path
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói t·∫°o file dataset.yaml: {e}")
            raise
    
    def verify_dataset_structure(self):
        """Ki·ªÉm tra c·∫•u tr√∫c dataset c√≥ ƒë√∫ng chu·∫©n YOLO kh√¥ng"""
        self.logger.info("="*50)
        self.logger.info("üîç ƒêang ki·ªÉm tra c·∫•u tr√∫c Dataset")
        self.logger.info("="*50)
        
        try:
            required_dirs = [
                "train/images",
                "train/labels", 
                "val/images",
                "val/labels"
            ]
            
            counts = {}
            errors = []
            
            for dir_path in required_dirs:
                full_path = self.data_path / dir_path
                if full_path.exists():
                    try:
                        files = [f for f in full_path.glob("*") if f.is_file()]
                        file_count = len(files)
                        counts[dir_path] = file_count
                        self.logger.info(f"‚úÖ {dir_path}: {file_count} files")
                        
                        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
                        if "images" in dir_path:
                            valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
                            invalid_files = [f for f in files if f.suffix.lower() not in valid_extensions]
                            if invalid_files:
                                errors.append(f"File ·∫£nh kh√¥ng h·ª£p l·ªá trong {dir_path}: {[f.name for f in invalid_files[:5]]}")
                                
                        elif "labels" in dir_path:
                            invalid_files = [f for f in files if f.suffix.lower() != '.txt']
                            if invalid_files:
                                errors.append(f"File label kh√¥ng h·ª£p l·ªá trong {dir_path}: {[f.name for f in invalid_files[:5]]}")
                                
                    except Exception as e:
                        errors.append(f"L·ªói ƒë·ªçc th∆∞ m·ª•c {dir_path}: {e}")
                        counts[dir_path] = 0
                else:
                    errors.append(f"Thi·∫øu th∆∞ m·ª•c: {dir_path}")
                    counts[dir_path] = 0
                    self.logger.error(f"‚ùå {dir_path}: Kh√¥ng t·ªìn t·∫°i!")
            
            # Ki·ªÉm tra t∆∞∆°ng ·ª©ng image-label
            train_images = counts.get('train/images', 0)
            train_labels = counts.get('train/labels', 0) 
            val_images = counts.get('val/images', 0)
            val_labels = counts.get('val/labels', 0)
            
            self.logger.info(f"\nüìä Ki·ªÉm tra t√≠nh nh·∫•t qu√°n d·ªØ li·ªáu:")
            self.logger.info(f"Train - Images: {train_images}, Labels: {train_labels} {'‚úÖ' if train_images == train_labels else '‚ùå'}")
            self.logger.info(f"Val - Images: {val_images}, Labels: {val_labels} {'‚úÖ' if val_images == val_labels else '‚ùå'}")
            
            # C·∫£nh b√°o
            if train_images == 0:
                errors.append("Kh√¥ng c√≥ ·∫£nh training!")
            if val_images == 0:
                errors.append("Kh√¥ng c√≥ ·∫£nh validation!")
            if train_images != train_labels:
                errors.append(f"S·ªë l∆∞·ª£ng ·∫£nh v√† label training kh√¥ng kh·ªõp: {train_images} vs {train_labels}")
            if val_images != val_labels:
                errors.append(f"S·ªë l∆∞·ª£ng ·∫£nh v√† label validation kh√¥ng kh·ªõp: {val_images} vs {val_labels}")
            
            # Ki·ªÉm tra n·ªôi dung label files
            self._validate_label_files()
            
            if errors:
                self.logger.error("‚ùå Ph√°t hi·ªán l·ªói trong dataset:")
                for error in errors:
                    self.logger.error(f"   ‚Ä¢ {error}")
                return False
            
            return train_images > 0 and val_images > 0
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói ki·ªÉm tra c·∫•u tr√∫c dataset: {e}")
            return False
    
    def _validate_label_files(self):
        """Ki·ªÉm tra n·ªôi dung c√°c file label"""
        try:
            for split in ['train', 'val']:
                labels_dir = self.data_path / split / "labels"
                if not labels_dir.exists():
                    continue
                    
                error_files = []
                for label_file in list(labels_dir.glob("*.txt"))[:10]:  # Ki·ªÉm tra 10 file ƒë·∫ßu
                    try:
                        with open(label_file, 'r') as f:
                            lines = f.readlines()
                            for i, line in enumerate(lines):
                                line = line.strip()
                                if not line:
                                    continue
                                parts = line.split()
                                if len(parts) != 5:
                                    error_files.append(f"{label_file.name}:line{i+1}")
                                    break
                                # Ki·ªÉm tra class_id
                                try:
                                    class_id = int(parts[0])
                                    if class_id not in [0, 1]:
                                        error_files.append(f"{label_file.name}:class_id={class_id}")
                                        break
                                except ValueError:
                                    error_files.append(f"{label_file.name}:invalid_class_id")
                                    break
                    except Exception as e:
                        error_files.append(f"{label_file.name}:read_error")
                
                if error_files:
                    self.logger.warning(f"‚ö†Ô∏è File label c√≥ v·∫•n ƒë·ªÅ trong {split}: {error_files[:5]}")
                    
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ki·ªÉm tra chi ti·∫øt label files: {e}")

    def analyze_dataset(self):
        """Ph√¢n t√≠ch th√†nh ph·∫ßn dataset"""
        self.logger.info("\n" + "="*50)
        self.logger.info("üìä Ph√¢n t√≠ch Dataset")
        self.logger.info("="*50)
        
        try:
            train_labels_dir = self.data_path / "train" / "labels"
            val_labels_dir = self.data_path / "val" / "labels"
            
            def count_classes(labels_dir, split_name):
                class_counts = {0: 0, 1: 0}  # no_phone: 0, using_phone: 1
                total_objects = 0
                empty_files = 0
                
                if not labels_dir.exists():
                    self.logger.warning(f"‚ö†Ô∏è Th∆∞ m·ª•c {split_name} labels kh√¥ng t·ªìn t·∫°i")
                    return class_counts, total_objects
                
                for label_file in labels_dir.glob("*.txt"):
                    try:
                        with open(label_file, 'r') as f:
                            lines = f.readlines()
                            if not lines or all(not line.strip() for line in lines):
                                empty_files += 1
                                continue
                                
                            for line in lines:
                                line = line.strip()
                                if line:
                                    try:
                                        class_id = int(line.split()[0])
                                        if class_id in class_counts:
                                            class_counts[class_id] += 1
                                            total_objects += 1
                                    except (ValueError, IndexError):
                                        self.logger.warning(f"‚ö†Ô∏è D√≤ng kh√¥ng h·ª£p l·ªá trong {label_file}: {line}")
                    except Exception as e:
                        self.logger.warning(f"‚ö†Ô∏è L·ªói ƒë·ªçc file {label_file}: {e}")
                
                self.logger.info(f"üìã {split_name}:")
                self.logger.info(f"  ‚Ä¢ Kh√¥ng d√πng ƒëi·ªán tho·∫°i: {class_counts[0]} objects")
                self.logger.info(f"  ‚Ä¢ ƒêang d√πng ƒëi·ªán tho·∫°i: {class_counts[1]} objects")
                self.logger.info(f"  ‚Ä¢ T·ªïng objects: {total_objects}")
                if empty_files > 0:
                    self.logger.warning(f"  ‚Ä¢ File label tr·ªëng: {empty_files}")
                    
                return class_counts, total_objects
            
            train_counts, train_total = count_classes(train_labels_dir, "Training")
            val_counts, val_total = count_classes(val_labels_dir, "Validation")
            
            # T√≠nh ph·∫ßn trƒÉm
            if train_total > 0:
                train_no_phone_pct = (train_counts[0] / train_total) * 100
                train_using_phone_pct = (train_counts[1] / train_total) * 100
                self.logger.info(f"üìä Ph√¢n b·ªë Training: Kh√¥ng d√πng {train_no_phone_pct:.1f}%, ƒêang d√πng {train_using_phone_pct:.1f}%")
                
            if val_total > 0:
                val_no_phone_pct = (val_counts[0] / val_total) * 100
                val_using_phone_pct = (val_counts[1] / val_total) * 100
                self.logger.info(f"üìä Ph√¢n b·ªë Validation: Kh√¥ng d√πng {val_no_phone_pct:.1f}%, ƒêang d√πng {val_using_phone_pct:.1f}%")
            
            # C·∫£nh b√°o n·∫øu d·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng
            if train_total > 0:
                imbalance_ratio = max(train_counts.values()) / min(train_counts.values()) if min(train_counts.values()) > 0 else float('inf')
                if imbalance_ratio > 3:
                    self.logger.warning(f"‚ö†Ô∏è D·ªØ li·ªáu training kh√¥ng c√¢n b·∫±ng (t·ª∑ l·ªá: {imbalance_ratio:.1f}:1)")
                    
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói ph√¢n t√≠ch dataset: {e}")

    def _optimize_training_params(self, batch_size, img_size):
        """T·ªëi ∆∞u tham s·ªë training d·ª±a tr√™n t√†i nguy√™n h·ªá th·ªëng"""
        try:
            # Ki·ªÉm tra VRAM n·∫øu d√πng GPU
            if self.device == 'cuda':
                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                
                if gpu_memory_gb < 6:  # VRAM th·∫•p
                    batch_size = min(batch_size, 16)
                    img_size = min(img_size, 416)
                    self.logger.warning(f"‚ö†Ô∏è VRAM th·∫•p, gi·∫£m batch_size={batch_size}, img_size={img_size}")
                elif gpu_memory_gb < 8:
                    batch_size = min(batch_size, 24)
                    
            # Ki·ªÉm tra RAM
            memory = psutil.virtual_memory()
            available_gb = memory.available / (1024**3)
            
            if available_gb < 4:
                batch_size = min(batch_size, 8)
                self.logger.warning(f"‚ö†Ô∏è RAM th·∫•p, gi·∫£m batch_size={batch_size}")
                
            return batch_size, img_size
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·ªëi ∆∞u tham s·ªë: {e}")
            return batch_size, img_size

    def train_model(self, epochs=100, img_size=640, batch_size=32, patience=50):
        """Train YOLOv8n model cho phone detection v·ªõi x·ª≠ l√Ω l·ªói to√†n di·ªán"""
        self.logger.info("\n" + "="*60)
        self.logger.info("üöÄ B·∫ÆT ƒê·∫¶U TRAINING YOLO PHONE DETECTION")
        self.logger.info("="*60)

        try:
            # Reset tr·∫°ng th√°i
            self.stop_training = False
            self.logger.info("‚úÖ ƒê√£ reset tr·∫°ng th√°i training")
            
            # T·ªëi ∆∞u tham s·ªë
            batch_size, img_size = self._optimize_training_params(batch_size, img_size)
            
            # T·∫°o dataset yaml
            self.logger.info("\nüìã ƒêang t·∫°o file c·∫•u h√¨nh dataset...")
            dataset_yaml = self.create_dataset_yaml()
            
            # Ki·ªÉm tra c·∫•u tr√∫c dataset  
            self.logger.info("\nüîç ƒêang ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu...")
            if not self.verify_dataset_structure():
                raise ValueError("C·∫•u tr√∫c d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá!")
                
            # Ph√¢n t√≠ch dataset
            self.analyze_dataset()
            
            # Ki·ªÉm tra model pretrained
            self._download_pretrained_model()
            
            # Kh·ªüi t·∫°o YOLO model
            self.logger.info(f"\n" + "="*50)
            self.logger.info("ü§ñ Kh·ªüi t·∫°o Model")
            self.logger.info("="*50)
            self.logger.info(f"üìÅ Loading YOLOv8n model: {self.model_path}")
            self.logger.info(f"üéÆ Training device: {self.device}")
            
            self.model = YOLO(self.model_path)
            
            # C·∫•u h√¨nh training v·ªõi x·ª≠ l√Ω l·ªói
            training_args = self._get_training_config(
                dataset_yaml, epochs, img_size, batch_size, patience
            )
            
            self._log_training_config(training_args)
            
            # B·∫Øt ƒë·∫ßu training v·ªõi error handling
            self.logger.info("\nüéØ B·∫ÆT ƒê·∫¶U TRAINING...")
            self.logger.info("="*50)
            
            results = self._execute_training(training_args)
            
            if results and not self.stop_training:
                self._post_training_tasks(results)
                return results
            else:
                self.logger.warning("‚ö†Ô∏è Training ƒë√£ b·ªã d·ª´ng ho·∫∑c th·∫•t b·∫°i")
                return None
                
        except KeyboardInterrupt:
            self.logger.info("\n‚èπÔ∏è Training b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng (Ctrl+C)")
            self.stop_training = True
            return None
        except Exception as e:
            self.logger.error(f"‚ùå Training th·∫•t b·∫°i: {e}")
            self._cleanup_on_error()
            return None
        finally:
            self._cleanup_after_training()

    def _download_pretrained_model(self):
        """T·∫£i model pretrained n·∫øu ch∆∞a c√≥"""
        try:
            if not Path(self.model_path).exists():
                self.logger.info(f"üì• ƒêang t·∫£i pretrained model: {self.model_path}")
                # YOLO s·∫Ω t·ª± ƒë·ªông t·∫£i model khi kh·ªüi t·∫°o
                temp_model = YOLO(self.model_path)
                self.logger.info("‚úÖ ƒê√£ t·∫£i xong pretrained model")
            else:
                self.logger.info("‚úÖ Pretrained model ƒë√£ t·ªìn t·∫°i")
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói t·∫£i pretrained model: {e}")
            raise

    def _get_training_config(self, dataset_yaml, epochs, img_size, batch_size, patience):
        """T·∫°o c·∫•u h√¨nh training v·ªõi c√°c tham s·ªë t·ªëi ∆∞u"""
        return {
            'data': str(dataset_yaml),
            'epochs': epochs,
            'imgsz': img_size,
            'batch': batch_size,
            'name': 'phone_detection',
            'project': str(self.output_path),
            'device': self.device,
            'workers': min(8, os.cpu_count() or 4),
            'patience': patience,
            'save': True,
            'save_period': 10,
            'cache': False,
            'optimizer': 'AdamW',
            'lr0': 0.01,
            'lrf': 0.1,
            'momentum': 0.937,
            'weight_decay': 0.0005,
            'warmup_epochs': 3,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            'cls': 0.5,
            'box': 7.5,
            'dfl': 1.5,
            'close_mosaic': 10,
            'resume': False,
            'amp': True,  # Automatic Mixed Precision
            'fraction': 1.0,
            'profile': False,
            'freeze': None,
            'multi_scale': False,
            'overlap_mask': True,
            'mask_ratio': 4,
            'dropout': 0.0,
            'val': True,
            'split': 'val',
            'save_json': False,
            'save_hybrid': False,
            'conf': None,
            'iou': 0.7,
            'max_det': 300,
            'half': False,
            'dnn': False,
            'plots': True,
            'source': None,
            'show': False,
            'save_txt': False,
            'save_conf': False,
            'save_crop': False,
            'show_labels': True,
            'show_conf': True,
            'vid_stride': 1,
            'stream_buffer': False,
            'line_width': None,
            'visualize': False,
            'augment': False,
            'agnostic_nms': False,
            'retina_masks': False,
            'boxes': True,
            'format': 'torchscript',
            'keras': False,
            'optimize': False,
            'int8': False,
            'dynamic': False,
            'simplify': False,
            'opset': None,
            'workspace': 4,
            'nms': False,
            'seed': 0,
            'deterministic': True,
            'single_cls': False,
            'rect': False,
            'cos_lr': False,
            'label_smoothing': 0.0,
            'nbs': 64,
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4,
            'degrees': 0.0,
            'translate': 0.1,
            'scale': 0.5,
            'shear': 0.0,
            'perspective': 0.0,
            'flipud': 0.0,
            'fliplr': 0.5,
            'mosaic': 1.0,
            'mixup': 0.0,
            'copy_paste': 0.0
        }

    def _log_training_config(self, training_args):
        """Log c·∫•u h√¨nh training"""
        self.logger.info("\n" + "="*50)
        self.logger.info("‚öôÔ∏è C·∫•u h√¨nh Training")
        self.logger.info("="*50)
        
        key_params = [
            'epochs', 'imgsz', 'batch', 'device', 'optimizer', 
            'lr0', 'patience', 'workers', 'cache'
        ]
        
        for key in key_params:
            if key in training_args:
                self.logger.info(f"  üìå {key}: {training_args[key]}")

    def _execute_training(self, training_args):
        """Th·ª±c hi·ªán training v·ªõi monitoring"""
        start_time = time.time()
        
        try:
            # Ch·∫°y training trong thread ri√™ng ƒë·ªÉ c√≥ th·ªÉ monitor
            results = self.model.train(**training_args)
            
            end_time = time.time()
            duration = end_time - start_time
            
            self.logger.info(f"\nüéâ Training ho√†n th√†nh th√†nh c√¥ng!")
            self.logger.info(f"‚è±Ô∏è Th·ªùi gian training: {duration/60:.1f} ph√∫t")
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh training: {e}")
            raise

    def _post_training_tasks(self, results):
        """C√°c t√°c v·ª• sau training"""
        try:
            results_dir = self.output_path / "phone_detection"
            
            if results_dir.exists():
                self.logger.info("\nüìä ƒêang t·∫°o bi·ªÉu ƒë·ªì v√† t·ªï ch·ª©c k·∫øt qu·∫£...")
                self.create_visualization_plots(results_dir)
                
                model_dir = Path("model") / "phone_detection5"
                self.create_summary_report(model_dir, results)
                
                self.logger.info("‚úÖ ƒê√£ ho√†n th√†nh t·∫•t c·∫£ t√°c v·ª• sau training")
                
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è L·ªói trong post-training tasks: {e}")

    def _cleanup_on_error(self):
        """D·ªçn d·∫πp khi c√≥ l·ªói"""
        try:
            # Gi·∫£i ph√≥ng GPU memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            # Gi·∫£i ph√≥ng RAM
            gc.collect()
            
            self.logger.info("üßπ ƒê√£ d·ªçn d·∫πp t√†i nguy√™n sau l·ªói")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ d·ªçn d·∫πp ho√†n to√†n: {e}")

    def _cleanup_after_training(self):
        """D·ªçn d·∫πp sau khi training k·∫øt th√∫c"""
        try:
            # Gi·∫£i ph√≥ng GPU memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            # Gi·∫£i ph√≥ng RAM
            gc.collect()
            
            self.logger.info("üßπ ƒê√£ d·ªçn d·∫πp t√†i nguy√™n")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è L·ªói d·ªçn d·∫πp: {e}")

    def create_visualization_plots(self, results_dir):
        """T·∫°o c√°c bi·ªÉu ƒë·ªì tr·ª±c quan h√≥a k·∫øt qu·∫£ training"""
        self.logger.info("\n" + "="*50)
        self.logger.info("üìä T·∫°o bi·ªÉu ƒë·ªì tr·ª±c quan")
        self.logger.info("="*50)
        
        try:
            plt.style.use('default')
            
            # ƒê·ªçc k·∫øt qu·∫£ training
            results_csv = results_dir / "results.csv"
            if not results_csv.exists():
                self.logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file results.csv")
                return
            
            df = pd.read_csv(results_csv)
            self.logger.info(f"‚úÖ ƒê√£ ƒë·ªçc {len(df)} epochs t·ª´ results.csv")
            
            # T·∫°o figure v·ªõi subplots
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('YOLOv8 Phone Detection - K·∫øt qu·∫£ Training', fontsize=16, y=0.98)
            
            # 1. Loss curves
            ax1 = axes[0, 0]
            if 'train/box_loss' in df.columns:
                ax1.plot(df.index, df['train/box_loss'], label='Train Box Loss', color='blue', alpha=0.7)
            if 'val/box_loss' in df.columns:
                ax1.plot(df.index, df['val/box_loss'], label='Val Box Loss', color='red', alpha=0.7)
            if 'train/cls_loss' in df.columns:
                ax1.plot(df.index, df['train/cls_loss'], label='Train Cls Loss', color='green', alpha=0.7)
            if 'val/cls_loss' in df.columns:
                ax1.plot(df.index, df['val/cls_loss'], label='Val Cls Loss', color='orange', alpha=0.7)
                
            ax1.set_title('Training v√† Validation Loss')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # 2. mAP metrics
            ax2 = axes[0, 1]
            if 'metrics/mAP50(B)' in df.columns:
                ax2.plot(df.index, df['metrics/mAP50(B)'], label='mAP50', color='purple', linewidth=2)
            if 'metrics/mAP50-95(B)' in df.columns:
                ax2.plot(df.index, df['metrics/mAP50-95(B)'], label='mAP50-95', color='brown', linewidth=2)
                
            ax2.set_title('mAP Metrics')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('mAP')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            ax2.set_ylim(0, 1)
            
            # 3. Precision v√† Recall
            ax3 = axes[1, 0]
            if 'metrics/precision(B)' in df.columns:
                ax3.plot(df.index, df['metrics/precision(B)'], label='Precision', color='darkgreen', linewidth=2)
            if 'metrics/recall(B)' in df.columns:
                ax3.plot(df.index, df['metrics/recall(B)'], label='Recall', color='darkred', linewidth=2)
                
            ax3.set_title('Precision v√† Recall')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Score')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            ax3.set_ylim(0, 1)
            
            # 4. Learning Rate
            ax4 = axes[1, 1]
            if 'lr/pg0' in df.columns:
                ax4.plot(df.index, df['lr/pg0'], label='Learning Rate', color='black', linewidth=2)
            ax4.set_title('Learning Rate')
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('LR')
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            ax4.set_yscale('log')
            
            plt.tight_layout()
            
            # L∆∞u bi·ªÉu ƒë·ªì
            plots_dir = results_dir / "custom_plots"
            plots_dir.mkdir(exist_ok=True)
            
            plot_path = plots_dir / "training_metrics.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {plot_path}")
            
            # T·∫°o bi·ªÉu ƒë·ªì so s√°nh classes
            self._create_class_performance_plot(df, plots_dir)
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì: {e}")
            plt.close('all')

    def _create_class_performance_plot(self, df, plots_dir):
        """T·∫°o bi·ªÉu ƒë·ªì hi·ªáu su·∫•t t·ª´ng class"""
        try:
            plt.figure(figsize=(12, 8))
            
            # T√¨m columns cho t·ª´ng class
            class_columns = {}
            for col in df.columns:
                if 'no_phone' in col.lower():
                    if 'precision' not in class_columns:
                        class_columns['precision'] = []
                    if 'recall' not in class_columns:
                        class_columns['recall'] = []
                    if 'precision' in col.lower():
                        class_columns['precision'].append(col)
                    elif 'recall' in col.lower():
                        class_columns['recall'].append(col)
            
            # Plot n·∫øu c√≥ data
            colors = ['blue', 'red', 'green', 'orange']
            for i, (metric, cols) in enumerate(class_columns.items()):
                for j, col in enumerate(cols):
                    if col in df.columns:
                        plt.plot(df.index, df[col], 
                                label=f'{metric.title()} - {col.split("/")[-1]}',
                                color=colors[(i*2+j) % len(colors)],
                                linewidth=2, alpha=0.8)
            
            plt.title('Hi·ªáu su·∫•t theo t·ª´ng Class', fontsize=14)
            plt.xlabel('Epoch')
            plt.ylabel('Score')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(True, alpha=0.3)
            plt.ylim(0, 1)
            
            plt.tight_layout()
            
            class_plot_path = plots_dir / "class_performance.png"
            plt.savefig(class_plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì class performance: {class_plot_path}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì class performance: {e}")
            plt.close('all')

    def create_summary_report(self, model_dir, results):
        """T·∫°o b√°o c√°o t·ªïng k·∫øt training"""
        self.logger.info("\nüìã T·∫°o b√°o c√°o t·ªïng k·∫øt...")
        
        try:
            model_dir.mkdir(parents=True, exist_ok=True)
            report_path = model_dir / "training_report.md"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# B√°o c√°o Training YOLOv8 Phone Detection\n\n")
                f.write(f"**Ng√†y t·∫°o:** {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("## Th√¥ng tin Model\n")
                f.write("- **Architecture:** YOLOv8n\n")
                f.write("- **Task:** Object Detection (Phone Usage)\n")
                f.write(f"- **Device:** {self.device}\n")
                f.write("- **Classes:** no_phone (0), using_phone (1)\n\n")
                
                f.write("## C·∫•u h√¨nh Training\n")
                if hasattr(results, 'args'):
                    args = results.args
                    f.write(f"- **Epochs:** {getattr(args, 'epochs', 'N/A')}\n")
                    f.write(f"- **Batch Size:** {getattr(args, 'batch', 'N/A')}\n")
                    f.write(f"- **Image Size:** {getattr(args, 'imgsz', 'N/A')}\n")
                    f.write(f"- **Optimizer:** {getattr(args, 'optimizer', 'N/A')}\n")
                    f.write(f"- **Learning Rate:** {getattr(args, 'lr0', 'N/A')}\n")
                
                f.write("\n## K·∫øt qu·∫£ Training\n")
                if hasattr(results, 'results_dict'):
                    metrics = results.results_dict
                    f.write(f"- **Best mAP50:** {metrics.get('metrics/mAP50(B)', 'N/A'):.4f}\n")
                    f.write(f"- **Best mAP50-95:** {metrics.get('metrics/mAP50-95(B)', 'N/A'):.4f}\n")
                    f.write(f"- **Precision:** {metrics.get('metrics/precision(B)', 'N/A'):.4f}\n")
                    f.write(f"- **Recall:** {metrics.get('metrics/recall(B)', 'N/A'):.4f}\n")
                
                f.write("\n## Files ƒë∆∞·ª£c t·∫°o\n")
                f.write("- `best.pt` - Model v·ªõi k·∫øt qu·∫£ t·ªët nh·∫•t\n")
                f.write("- `last.pt` - Model ·ªü epoch cu·ªëi\n")
                f.write("- `results.csv` - Chi ti·∫øt metrics t·ª´ng epoch\n")
                f.write("- `confusion_matrix.png` - Ma tr·∫≠n nh·∫ßm l·∫´n\n")
                f.write("- `training_metrics.png` - Bi·ªÉu ƒë·ªì training\n")
                
                f.write("\n## C√°ch s·ª≠ d·ª•ng\n")
                f.write("```python\n")
                f.write("from ultralytics import YOLO\n")
                f.write("model = YOLO('path/to/best.pt')\n")
                f.write("results = model('path/to/image.jpg')\n")
                f.write("```\n")
            
            self.logger.info(f"‚úÖ ƒê√£ t·∫°o b√°o c√°o: {report_path}")
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói t·∫°o b√°o c√°o: {e}")

    def copy_best_model(self):
        """Copy model t·ªët nh·∫•t v√†o th∆∞ m·ª•c model"""
        try:
            results_dir = self.output_path / "phone_detection"
            weights_dir = results_dir / "weights"
            
            if not weights_dir.exists():
                self.logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c weights")
                return False
            
            best_model = weights_dir / "best.pt" 
            last_model = weights_dir / "last.pt"
            
            model_dir = Path("model")
            model_dir.mkdir(exist_ok=True)
            
            if best_model.exists():
                shutil.copy2(best_model, model_dir / "phone_detection_best.pt")
                self.logger.info(f"‚úÖ ƒê√£ copy best model: {model_dir / 'phone_detection_best.pt'}")
                
            if last_model.exists():
                shutil.copy2(last_model, model_dir / "phone_detection_last.pt") 
                self.logger.info(f"‚úÖ ƒê√£ copy last model: {model_dir / 'phone_detection_last.pt'}")
                
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói copy model: {e}")
            return False

    def evaluate_model(self, model_path=None):
        """ƒê√°nh gi√° model tr√™n validation set"""
        self.logger.info("\n" + "="*50)
        self.logger.info("üîç ƒê√°nh gi√° Model")
        self.logger.info("="*50)
        
        try:
            if model_path is None:
                model_path = Path("model") / "phone_detection_best.pt"
                
            if not Path(model_path).exists():
                self.logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y model: {model_path}")
                return None
                
            # Load model
            model = YOLO(model_path)
            self.logger.info(f"‚úÖ ƒê√£ load model: {model_path}")
            
            # ƒê√°nh gi√° tr√™n validation set
            dataset_yaml = self.data_path / "dataset.yaml"
            if not dataset_yaml.exists():
                dataset_yaml = self.create_dataset_yaml()
                
            results = model.val(data=str(dataset_yaml), device=self.device)
            
            self.logger.info("üìä K·∫øt qu·∫£ ƒë√°nh gi√°:")
            self.logger.info(f"  ‚Ä¢ mAP50: {results.box.map50:.4f}")
            self.logger.info(f"  ‚Ä¢ mAP50-95: {results.box.map:.4f}")
            self.logger.info(f"  ‚Ä¢ Precision: {results.box.mp:.4f}")
            self.logger.info(f"  ‚Ä¢ Recall: {results.box.mr:.4f}")
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói ƒë√°nh gi√° model: {e}")
            return None

    def predict_image(self, image_path, model_path=None, conf_threshold=0.5):
        """D·ª± ƒëo√°n tr√™n m·ªôt ·∫£nh"""
        try:
            if model_path is None:
                model_path = Path("model") / "phone_detection_best.pt"
                
            if not Path(model_path).exists():
                self.logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y model: {model_path}")
                return None
                
            # Load model
            model = YOLO(model_path)
            
            # D·ª± ƒëo√°n
            results = model(image_path, conf=conf_threshold, device=self.device)
            
            self.logger.info(f"‚úÖ ƒê√£ d·ª± ƒëo√°n ·∫£nh: {image_path}")
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            for result in results:
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    self.logger.info(f"üì± Ph√°t hi·ªán {len(boxes)} objects:")
                    for i, box in enumerate(boxes):
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        class_name = "using_phone" if class_id == 1 else "no_phone"
                        self.logger.info(f"  ‚Ä¢ Object {i+1}: {class_name} (confidence: {confidence:.3f})")
                else:
                    self.logger.info("üì± Kh√¥ng ph√°t hi·ªán object n√†o")
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói d·ª± ƒëo√°n: {e}")
            return None

    def monitor_training_progress(self):
        """Monitor ti·∫øn tr√¨nh training"""
        try:
            results_dir = self.output_path / "phone_detection"
            results_csv = results_dir / "results.csv"
            
            if not results_csv.exists():
                return None
                
            df = pd.read_csv(results_csv)
            latest_epoch = len(df) - 1
            
            if latest_epoch >= 0:
                latest_metrics = df.iloc[-1]
                
                progress_info = {
                    'epoch': latest_epoch,
                    'train_loss': latest_metrics.get('train/box_loss', 0),
                    'val_loss': latest_metrics.get('val/box_loss', 0),
                    'mAP50': latest_metrics.get('metrics/mAP50(B)', 0),
                    'precision': latest_metrics.get('metrics/precision(B)', 0),
                    'recall': latest_metrics.get('metrics/recall(B)', 0)
                }
                
                return progress_info
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ monitor progress: {e}")
            return None

def main():
    """H√†m main ƒë·ªÉ ch·∫°y training"""
    print("üöÄ YOLOv8 Phone Detection Trainer - Phi√™n b·∫£n c·∫£i ti·∫øn")
    print("="*60)
    
    try:
        # Kh·ªüi t·∫°o trainer
        trainer = PhoneDetectionTrainer(
            data_path="data",
            output_path="runs/detect", 
            use_gpu=True
        )
        
        print("\nüìã Menu ch·ª©c nƒÉng:")
        print("1. Ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu")
        print("2. Ph√¢n t√≠ch dataset")
        print("3. Training model")
        print("4. ƒê√°nh gi√° model")
        print("5. D·ª± ƒëo√°n ·∫£nh")
        print("6. Tho√°t")
        
        while True:
            try:
                choice = input("\nüëâ Ch·ªçn ch·ª©c nƒÉng (1-6): ").strip()
                
                if choice == '1':
                    trainer.verify_dataset_structure()
                    
                elif choice == '2':
                    trainer.analyze_dataset()
                    
                elif choice == '3':
                    print("\n‚öôÔ∏è C·∫•u h√¨nh training:")
                    epochs = int(input("S·ªë epochs (m·∫∑c ƒë·ªãnh 100): ") or "100")
                    batch_size = int(input("Batch size (m·∫∑c ƒë·ªãnh 32): ") or "32")
                    img_size = int(input("Image size (m·∫∑c ƒë·ªãnh 640): ") or "640")
                    patience = int(input("Patience (m·∫∑c ƒë·ªãnh 50): ") or "50")
                    
                    print(f"\nüéØ B·∫Øt ƒë·∫ßu training v·ªõi:")
                    print(f"  ‚Ä¢ Epochs: {epochs}")
                    print(f"  ‚Ä¢ Batch size: {batch_size}")
                    print(f"  ‚Ä¢ Image size: {img_size}")
                    print(f"  ‚Ä¢ Patience: {patience}")
                    
                    results = trainer.train_model(
                        epochs=epochs,
                        batch_size=batch_size, 
                        img_size=img_size,
                        patience=patience
                    )
                    
                    if results:
                        trainer.copy_best_model()
                        print("\nüéâ Training ho√†n th√†nh th√†nh c√¥ng!")
                    else:
                        print("\n‚ùå Training th·∫•t b·∫°i ho·∫∑c b·ªã d·ª´ng")
                
                elif choice == '4':
                    trainer.evaluate_model()
                    
                elif choice == '5':
                    image_path = input("ƒê∆∞·ªùng d·∫´n ·∫£nh: ").strip()
                    if image_path and Path(image_path).exists():
                        conf = float(input("Confidence threshold (0.5): ") or "0.5")
                        trainer.predict_image(image_path, conf_threshold=conf)
                    else:
                        print("‚ùå ·∫¢nh kh√¥ng t·ªìn t·∫°i!")
                        
                elif choice == '6':
                    print("üëã T·∫°m bi·ªát!")
                    break
                    
                else:
                    print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
                    
            except KeyboardInterrupt:
                print("\n‚èπÔ∏è ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh")
                break
            except Exception as e:
                print(f"‚ùå L·ªói: {e}")
                
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")

if __name__ == "__main__":
    main()